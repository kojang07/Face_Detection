{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca24f829-fdd4-4344-b1cb-c578df761d02",
   "metadata": {},
   "source": [
    "### 아래 내용은 글로벌 기업 (주)인텔에서 개발한 <br> Intel® AI for Youth Program 내용을 \n",
    "대한민국 Implementation Partner사인 (주)Brain AI와 Brain AI Lead Coach Network에서 우리나라 초, 중, 고 학생들의 AI 교육을 위해 현지화 한 내용입니다. <br>\n",
    "(주)Brain AI와 NDA를 체결한 학교에서만 사용 가능하며 NDA를 준수해야합니다. <br>\n",
    "상업적 사용은 불가하며, 학교내에서 학생들 교육활동에 자유롭게 사용가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f866f4f-4bcc-426d-ad39-b9309f48d6ed",
   "metadata": {},
   "source": [
    "## 프로젝트 제목: BrainAI 얼굴 인식 AI 시스템 만들기\n",
    "### Intel OpenVINO Pre-trained 모델을 활용하여 얼굴 인식 AI 시스템 개발 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f28b70-72ad-4737-90f1-7be94ef6e532",
   "metadata": {},
   "source": [
    "## 1. Open-Model-Zoo 모델 다운로드\n",
    "\n",
    "### Task 1. 사용할 모델 문서를 참조하고 모델의 입력 및 출력을 알아봅시다.\n",
    "\n",
    "얼굴 인식 모델(face-detection-adas-0001)에 대해서 [여기](https://docs.openvino.ai/2022.1/omz_models_model_face_detection_adas_0001.html)에서 알아봅니다.\n",
    "\n",
    "<img src=\"https://docs.openvino.ai/2022.1/_images/face-detection-adas-0001.png\" style=\"width:400px; float:left;\" />\n",
    "<div style=\"clear:both;\"></div>\n",
    "\n",
    "네트워크(모델)는 모양이 [1, 1, N, 7] 인 blob을 출력합니다. <br>\n",
    "여기서 N은 감지 된 경계 상자의 수입니다. 각 탐지에 대해 설명은 다음과 같은 형식을 갖습니다.<br>\n",
    "<b>[image_id, label, conf, x_min, y_min, x_max, y_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893924ba-4bcd-4515-bcdc-ed0e037ba030",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "A very basic introduction to using face detection models with OpenVINO™ \n",
    "\n",
    "The [Model/face-detection-adas-0001](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/face-detection-adas-0001/README.md) model from [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo/) is used. It detects faces in images and returns a blob of data \n",
    "\n",
    "with shape: `1, 1, 200, 7` in the format `1, 1, N, 7`, where `N` is the number of detected\n",
    "bounding boxes. The results are sorted by confidence in decreasing order. Each detection has the format\n",
    "[`image_id`, `label`, `conf`, `x_min`, `y_min`, `x_max`, `y_max`], where:\n",
    "\n",
    "- `image_id` - ID of the image in the batch\n",
    "- `label` - predicted class ID (1 - face)\n",
    "- `conf` - confidence for the predicted class\n",
    "- (`x_min`, `y_min`) - coordinates of the top left bounding box corner\n",
    "- (`x_max`, `y_max`) - coordinates of the bottom right bounding box corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c12b27-8a36-43f3-b48e-07ed6ad57984",
   "metadata": {},
   "source": [
    "### Task 2. 사용할 모델을 omz_downloader를 사용하여 다운로드해 봅시다.\n",
    "\n",
    "#### 2.1 omz_downloader 옵션 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3140429a-e255-4988-b275-ddafa2e3e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "! omz_downloader -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eed587-2385-455f-9d5d-5a6fdeb690db",
   "metadata": {},
   "source": [
    "#### 2.2 사용가능한 모든 models 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740141b6-a707-4307-8941-a35578ecc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! omz_downloader --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa34d2-bdbf-4b83-bbbc-aa4650cb40b6",
   "metadata": {},
   "source": [
    "#### 2.3 'face detection for ADAS' model 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab5a18-f55c-4e66-9520-59f3c86897c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! omz_downloader --name face-detection-adas-0001 --precision FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2e9a3-9434-4d07-bbe6-71931422b5ae",
   "metadata": {},
   "source": [
    "#### 2.4 다운로드한 모델을 model 폴더로 복사\n",
    "\n",
    "'Intel'폴더에 다운로드한 모델 파일 'face-detection-adas-0001.bin', 'face-detection-adas-0001.xml' 을 프로젝트 폴더 안의 'models' 폴더로 복사합니다.\n",
    "\n",
    "<img src=\"images/file_copy.jpg\" style=\"width:400px; float:left;\" />\n",
    "<div style=\"clear:both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3bb23-f3b9-4844-afd5-10e036572790",
   "metadata": {},
   "source": [
    "### Task 3. 'face-detection-adas-0001' 모델을 사용하여 얼굴 인식을 해봅시다.\n",
    "\n",
    "#### 3-1. 사용할 OpenVino Model Zoo 불러와서 입출력값 확인하기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e2ceccf-0001-47d6-a633-9a2bda99c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59013016-7854-4cb2-8964-866f915f2d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape:  [1,3,384,672]\n",
      "Output layer shape: [1,1,200,7]\n"
     ]
    }
   ],
   "source": [
    "core = ov.Core()\n",
    "\n",
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)\n",
    "print(\"Input layer shape: \", face_input_layer.shape)\n",
    "print(\"Output layer shape:\", face_output_layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0abbc9-5a4e-496c-b042-88dfc37045da",
   "metadata": {},
   "source": [
    "#### 3-2. 사용할 이미지(데이터) 불러와서 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60cf2694-e87a-400b-a9f4-529248dd9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frame = cv2.imread(\"images/test.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20d1ed5a-0c91-4083-b9c0-fd2bbdaa528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_frame = cv2.resize(src=frame, dsize=(672, 384)) \n",
    "transposed_frame = resized_frame.transpose(2, 0, 1)\n",
    "input_frame = np.expand_dims(transposed_frame, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff208f-14ef-40df-9ee4-6e30107b1103",
   "metadata": {},
   "source": [
    "#### 3-3. 추론(Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00944ffa-cf7a-4087-9d2c-de0dcfaad0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_output = face_model([input_frame])[face_output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a3e91-f81a-46d9-882c-6fa5a24c83c1",
   "metadata": {},
   "source": [
    "#### 3-4. 배포(Deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfb79bb6-e9cc-44e0-9a1d-f159f4ddca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추론한 값(output), 이미지(image), 임계값(conf)을 가져와 \n",
    "#이미지에 얼굴에 박스를 그리는 DrawBoundingBoxes함수\n",
    "def DrawBoundingBoxes(output, image, conf):\n",
    "\n",
    "    canvas = image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "\n",
    "    predictions = output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "708ca67a-0d91-425d-8e20-cd7ab5b6d2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "canvas = DrawBoundingBoxes(face_output, frame, conf=0.5)\n",
    "\n",
    "cv2.imshow(\"Deployment\", canvas)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a797d-410d-427d-832b-2097c906cf02",
   "metadata": {},
   "source": [
    "### Task 4. 배경이미지에 결과 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "289e220a-7086-4c99-9606-b634376168ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddBackground(frame, bg):\n",
    "\n",
    "    frame_h, frame_w = frame.shape[0], frame.shape[1]\n",
    "    new_h = 500\n",
    "    new_w = int((new_h/frame_h)*frame_w)\n",
    "    frame_resize = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "    xmax = bg.shape[1] - 300\n",
    "    ymax = bg.shape[0] - 175\n",
    "    xmin = xmax - new_w\n",
    "    ymin = ymax - new_h\n",
    "\n",
    "    bg[ymin:ymax, xmin:xmax] = frame_resize\n",
    "\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43749350-e9b4-4e7a-a95d-0c63f6591fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = \"./images/Background.jpg\"  #사용할 배경화면 경로\n",
    "canvas = DrawBoundingBoxes(face_output, frame, conf=0.5)  \n",
    "bg = cv2.imread(background)\n",
    "\n",
    "deployment = AddBackground(canvas, bg)\n",
    "cv2.imshow(\"Deployment\", deployment)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79505c-014a-44e9-b6ce-df581cab8d62",
   "metadata": {},
   "source": [
    "### Task 5. 영상(Webcam) 입력받아 얼굴 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d0e445b-4d5c-4b5d-9aa4-d89be8958955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "camera = cv2.VideoCapture('./images/people.mp4')\n",
    "background = \"./images/Background.jpg\"\n",
    "bg = cv2.imread(background)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    resized_frame = cv2.resize(src=frame, dsize=(672, 384)) \n",
    "    transposed_frame = resized_frame.transpose(2, 0, 1)\n",
    "    input_frame = np.expand_dims(transposed_frame, 0)    \n",
    "    \n",
    "    face_output = face_model([input_frame])[face_output_layer]\n",
    "\n",
    "    canvas = DrawBoundingBoxes(face_output, frame, conf=0.5)\n",
    "    deployment = AddBackground(canvas, bg)\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit', deployment)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436327c4-65fc-4b65-9129-e1f69fd3ae4f",
   "metadata": {},
   "source": [
    "### Task 6. Gradio 사용하여 결과 출력하기\n",
    "\n",
    "#### 6-1. 웹에서 이미지 입력받아 결과 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fdde7-9fe5-4c71-9994-ea10ebfe292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_images(input_img):\n",
    "    canvas = DrawBoundingBoxes(face_output, input_img, conf=0.5)\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a595bd-fdfa-45b5-96a2-8e8720cf81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(input_images, gr.Image(), \"image\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e2bfb-6e68-4e5c-9c89-3618c6272c90",
   "metadata": {},
   "source": [
    "#### 6-2. 웹에서 캠으로 영상받아서 결과 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f07278-7dd6-4682-b659-bb9183f3eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "background = \"./images/Background.jpg\"\n",
    "bg = cv2.imread(background)\n",
    "\n",
    "def flip(input_image):\n",
    "    canvas = DrawBoundingBoxes(face_output, np.flip(input_image, 1), conf=0.5)\n",
    "    #canvas = DrawBoundingBoxes(face_output, input_image, conf=0.5)\n",
    "    return AddBackground(canvas, bg)\n",
    "''''''''''''''''''''''''\n",
    "#deployment = AddBackground(canvas, bg)\n",
    "\n",
    "demo = gr.Interface(flip, gr.Image(sources=[\"webcam\"], streaming=True), \"image\", live=True )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370f41b-8167-47c8-8b6a-d5f4740168f6",
   "metadata": {},
   "source": [
    "### 추가 미션. Hello Bot 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023ca0d-7698-4a8c-91f8-91aec6e0820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#소리를 출력하기 위해  playsound 라이브러리 설치 <미설치시 사용>\n",
    "#!pip install playsound==1.2.2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953a8d2-f6cf-405f-844e-d87fc3a4d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "file_path = './sound/hello.mp3'   #소리 파일 경로 지정\n",
    " \n",
    "def sayHello():       # 설정한 경로에서 실행할 파일 스피커로 출력하는 함수\n",
    "    playsound(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b010af-8779-4ab0-8ad4-4ca95e88c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(output, image, conf):\n",
    "\n",
    "    canvas = image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "\n",
    "    predictions = output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "        \n",
    "        detect = 1   # 얼굴인식 여부 1:인식, 0: 미인식\n",
    "    return canvas, detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52b7b5-3c83-4aeb-9c98-25366d4f3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_check = 0   #얼굴 인식 여부 확인 변수(0:미인식, 1:인식)\n",
    "frame = cv2.imread(\"images/test.jpeg\")\n",
    "canvas, detect_check = DrawBoundingBoxes(face_output, frame, conf=0.5)\n",
    " \n",
    "cv2.imshow(\"Person\", canvas)\n",
    "\n",
    "if detect_check == 1:  #얼굴 인식되었으면 소리 출력\n",
    "    sayHello()\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7fee8-3bd6-4998-8b9e-78a6d2eabf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
